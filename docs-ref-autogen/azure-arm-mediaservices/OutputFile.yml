### YamlMime:UniversalReference
ms.openlocfilehash: f4ecb7ab933b794f77479de848453841eb3da99c
ms.sourcegitcommit: ce76ec3eda83746ef9a765165173b5c00b5b7df6
ms.translationtype: MT
ms.contentlocale: es-ES
ms.lasthandoff: 12/20/2018
ms.locfileid: "53664089"
items:
- uid: azure-arm-mediaservices.OutputFile
  name: OutputFile
  fullName: OutputFile
  children:
  - azure-arm-mediaservices.OutputFile.labels
  langs:
  - typeScript
  type: interface
  summary: <span data-ttu-id="bb194-101">Representa un archivo de salida generado.</span><span class="sxs-lookup"><span data-stu-id="bb194-101">Represents an output file produced.</span></span>
  package: azure-arm-mediaservices
- uid: azure-arm-mediaservices.OutputFile.labels
  name: labels
  fullName: labels
  children: []
  langs:
  - typeScript
  type: property
  summary: <span data-ttu-id="bb194-102">La lista de etiquetas que describen cómo el codificador debe multiplexar audio y vídeo en un archivo de salida.</span><span class="sxs-lookup"><span data-stu-id="bb194-102">The list of labels that describe how the encoder should multiplex video and audio into an output file.</span></span> <span data-ttu-id="bb194-103">Por ejemplo, si está generando el codificador de dos capas de vídeo con etiquetas v1 y v2 y una capa de audio con etiqueta a1, una matriz como '[v1, a1]' indica al codificador para generar un archivo de salida con la pista de vídeo representada por v1 y la pista de audio representado por a1.</span><span class="sxs-lookup"><span data-stu-id="bb194-103">For example, if the encoder is producing two video layers with labels v1 and v2, and one audio layer with label a1, then an array like '[v1, a1]' tells the encoder to produce an output file with the video track represented by v1 and the audio track represented by a1.</span></span>
  optional: true
  syntax:
    content: 'labels?: string[]'
    return:
      type:
      - string[]
  package: azure-arm-mediaservices
